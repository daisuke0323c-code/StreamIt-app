# -*- coding: utf-8 -*-
import json
import os
import uuid
from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional

import streamlit as st

# å–è¾¼ç”¨ï¼ˆå­˜åœ¨ã—ãªã‘ã‚Œã°ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
try:
    import pandas as pd
except Exception:
    pd = None

try:
    from docx import Document
except Exception:
    Document = None  # python-docx ãŒç„¡ã‘ã‚Œã°ãƒ—ãƒ¬ãƒ¼ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯

import re
import tempfile
from pathlib import Path

try:
    import pypandoc
except Exception:
    pypandoc = None

# Web å–ã‚Šè¾¼ã¿ç”¨ï¼ˆå­˜åœ¨ã—ãªã‘ã‚Œã°ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
try:
    import requests
except Exception:
    requests = None

try:
    import trafilatura
except Exception:
    trafilatura = None

try:
    from readability import Document as ReadabilityDocument
except Exception:
    ReadabilityDocument = None

try:
    from bs4 import BeautifulSoup
except Exception:
    BeautifulSoup = None

try:
    import html2text as _h2t
except Exception:
    _h2t = None


# ============ ã‚¹ã‚¿ã‚¤ãƒ«/CSS ============
st.markdown("""
<style>
/* ãƒˆãƒƒãƒ—ãƒãƒ¼ï¼ˆè–„ã„ã‚«ãƒ—ã‚»ãƒ«ï¼‰ */
.agent-topbar{
  display:flex; align-items:center; justify-content:space-between; gap:8px;
  padding:6px 10px;
  border-radius: 999px;
  border: 1px solid rgba(120,140,180,.25);
  background: rgba(80,120,200,.06);
}
[data-theme="dark"] .agent-topbar{
  border-color: rgba(120,160,220,.15);
  background: rgba(80,140,240,.08);
}
.agent-topbar.is-current{
  background: rgba(90,140,240,.12);
  border-color: rgba(120,160,240,.28);
}

/* ã‚¿ã‚¤ãƒˆãƒ«ã¨å°ãƒãƒƒãƒ— */
.agent-title{ display:flex; align-items:center; gap:8px; font-weight:700; letter-spacing:.2px; }
.agent-chip{
  font-size: 11px; padding: 2px 8px; border-radius:999px;
  background: rgba(90,140,240,.18); color:#2e6fed; border:1px solid rgba(90,140,240,.35);
}
[data-theme="dark"] .agent-chip{ color:#9cc0ff; }

/* ç¾åœ¨è¡Œç”¨ã®æ§ãˆã‚ãƒãƒƒãƒ— */
.agent-badge-current{
  font-size: 11px; padding:2px 8px; border-radius:999px;
  background: rgba(90,140,240,.14); color:#2e6fed; border:1px solid rgba(90,140,240,.28);
}

/* ãƒŸãƒ‹ãƒœã‚¿ãƒ³è¡Œ */
.btn-row{ display:grid; grid-template-columns: repeat(4, 1fr); gap:6px; margin-top:6px; }
.small-btn button{ padding:.2rem .35rem !important; font-size:.9rem !important; border-radius:10px !important; }

/* ãƒ¡ã‚¿è¡Œï¼ˆIDï¼‰ */
.enabled-line{ display:flex; align-items:center; gap:8px; margin-top:4px; }
.enabled-badge{
  font-size: 11px; padding: 2px 8px; border-radius:999px; border:1px solid rgba(128,140,160,.35);
  background: rgba(150,170,200,.12);
}
[data-theme="dark"] .enabled-badge{ border-color: rgba(120,140,180,.35); background: rgba(120,140,180,.12); }

/* Expander ã‚’è»½ãã‚«ãƒ¼ãƒ‰é¢¨ */
[data-testid="stExpander"]{ border-radius:12px; border:1px solid rgba(128,128,128,.25); }

/* è¡Œæ“ä½œãƒœã‚¿ãƒ³ã‚’å°‘ã—è©°ã‚ã‚‹ */
.step-toolbar button { padding:0.2rem 0.4rem; font-size:0.9rem }
</style>
""", unsafe_allow_html=True)


# ============ ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ============
def safe_rerun():
    try:
        st.rerun()
    except Exception:
        try:
            st.experimental_rerun()
        except Exception:
            pass

def json_pretty(obj: Any) -> str:
    try:
        return json.dumps(obj, ensure_ascii=False, indent=2)
    except Exception:
        return str(obj)

def force_parse_json(text: str) -> Optional[Any]:
    if text is None:
        return None
    if "```" in text:
        parts = text.split("```")
        for i in range(1, len(parts), 2):
            body = parts[i]
            try:
                return json.loads(body)
            except Exception:
                pass
    stack = []
    start = None
    for i, ch in enumerate(text):
        if ch in "{[":
            if not stack:
                start = i
            stack.append(ch)
        elif ch in "}]":
            if not stack:
                continue
            op = stack.pop()
            if (op == "{" and ch != "}") or (op == "[" and ch != "]"):
                stack = []
                start = None
                continue
            if not stack and start is not None:
                cand = text[start:i+1]
                try:
                    return json.loads(cand)
                except Exception:
                    start = None
    return None

def normalize_unified(parsed: Any) -> Dict[str, Any]:
    if isinstance(parsed, dict):
        if any(k in parsed for k in ("ok", "message", "kv_patch", "meta")):
            return {
                "ok": bool(parsed.get("ok", True)),
                "message": parsed.get("message") or {},
                "kv_patch": parsed.get("kv_patch") or {},
                "meta": parsed.get("meta") or {},
            }
        return {"ok": True, "message": parsed, "kv_patch": {}, "meta": {}}
    elif parsed is None:
        return {"ok": False, "message": {"error": "parse_failed"}, "kv_patch": {}, "meta": {}}
    else:
        return {"ok": True, "message": {"value": parsed}, "kv_patch": {}, "meta": {}}


# ============ ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆåˆ©ç”¨è€…ä¸å¯ï¼‰ ============
SCHEMA_ENFORCER = (
    "ä»¥ä¸‹ã®åˆ¶ç´„ã‚’å³å®ˆ:\n"
    "- å‡ºåŠ›ã¯æœ‰åŠ¹ãªJSONã®ã¿ï¼ˆå‰ç½®ãã‚„ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ç¦æ­¢ï¼‰\n"
    "- ã‚¹ã‚­ãƒ¼ãƒ:\n"
    "{ \"ok\": true, \"message\": {...}, \"kv_patch\": {...}, \"meta\": {...} }\n"
)


# ============ Markdown ç›®æ¬¡ç”Ÿæˆ ============
def compute_doc_index(md: str) -> Dict[str, Any]:
    if not isinstance(md, str):
        md = str(md or "")
    lines = md.splitlines()
    flat = []
    stack = []
    toc = {"title": "ROOT", "children": []}
    stack.append((0, toc))
    anchor_counts: Dict[str, int] = {}

    def slugify(title: str) -> str:
        t = re.sub(r"[^\w\-ä¸€-é¾ ã-ã‚“ã‚¡-ãƒ³ãƒ¼]+", "-", title.strip()).strip("-").lower()
        if not t:
            t = "section"
        cnt = anchor_counts.get(t, 0) + 1
        anchor_counts[t] = cnt
        return t if cnt == 1 else f"{t}-{cnt}"

    for ln in lines:
        m = re.match(r"^(#{1,6})\s+(.+?)\s*$", ln)
        if not m:
            continue
        level = len(m.group(1))
        title = m.group(2).strip()
        anchor = slugify(title)
        node = {"title": title, "level": level, "anchor": anchor, "children": []}
        flat.append({"level": level, "title": title, "anchor": anchor})
        while stack and stack[-1][0] >= level:
            stack.pop()
        parent_level, parent_node = stack[-1]
        parent_node["children"].append(node)
        stack.append((level, node))
    return {"flat": flat, "toc": toc}


# ============ ãƒã‚¯ãƒ­å±•é–‹ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ============
def _to_int_or_none(s: str) -> Optional[int]:
    try:
        return int(s)
    except Exception:
        return None

def deep_get(obj: Any, path: str) -> Any:
    if not path:
        return obj
    cur = obj
    for part in path.split("."):
        if cur is None:
            return None
        if isinstance(cur, dict):
            if part in cur:
                cur = cur[part]
            else:
                i = _to_int_or_none(part)
                if i is not None and str(i) in cur:
                    cur = cur[str(i)]
                else:
                    return None
        elif isinstance(cur, list):
            i = _to_int_or_none(part)
            if i is None or not (0 <= i < len(cur)):
                return None
            cur = cur[i]
        else:
            return None
    return cur

def _get_prev_row_cells(ctx: Dict[str, Any]) -> List[Dict[str, Any]]:
    resp = (ctx or {}).get("resp") or {}
    if not isinstance(resp, dict):
        return []
    prev = resp.get("-1") or []
    return prev if isinstance(prev, list) else []

def summarize_prev_row(ctx: Dict[str, Any]) -> List[Dict[str, Any]]:
    cells = _get_prev_row_cells(ctx)
    out = []
    for cell in cells:
        out.append({
            "name": cell.get("name"),
            "agent_id": cell.get("agent_id"),
            "message": cell.get("message"),
            "raw": cell.get("raw"),
        })
    return out

def find_judge_results(ctx: Dict[str, Any]) -> Any:
    resp = (ctx or {}).get("resp") or {}
    if not isinstance(resp, dict):
        return None
    keys = []
    for k in resp.keys():
        try:
            keys.append(int(k))
        except Exception:
            pass
    keys = sorted([k for k in keys if k < 0], reverse=True)
    results = []
    for k in keys:
        cells = resp.get(str(k)) or []
        for cell in cells:
            name = (cell.get("name") or "").lower()
            if "judge" in name:
                v = cell.get("message") or cell.get("raw")
                if v is not None:
                    results.append(v)
        if results:
            break
    if not results:
        return None
    return results[0] if len(results) == 1 else results

def _get_prev_first_response(ctx: Dict[str, Any]) -> Any:
    cells = _get_prev_row_cells(ctx)
    if not cells:
        return None
    cell = cells[0]
    return cell.get("message") or cell.get("raw")

def _get_prev_first_prompt_text(row_idx: int) -> Optional[str]:
    try:
        if row_idx <= 0:
            return None
        prev_row = st.session_state.grid[row_idx - 1]
        if not prev_row:
            return None
        ag_prev_first = prev_row[0]
        for item in reversed(ag_prev_first.history):
            if item.get("role") == "user":
                return item.get("content")
        return None
    except Exception:
        return None

def normalize_context_path(p: str) -> str:
    if not isinstance(p, str):
        return ""
    s = re.sub(r"\s+", "", p)
    def repl(m):
        g1, g2, g3 = m.group(1), m.group(2), m.group(3)
        if g1 is not None: return "." + g1
        if g2 is not None: return "." + g2
        if g3 is not None: return "." + g3
        return ""
    s = re.sub(r'\[(?:"([^"]+)"|\'([^\']+)\'|(-?\d+))\]', repl, s)
    s = re.sub(r"\.+", ".", s).lstrip(".")
    return s

def expand_prompt_macros(prompt: str, ctx: Dict[str, Any], row_idx: Optional[int] = None) -> str:
    if prompt is None:
        return ""
    s = prompt.replace("ï½›", "{").replace("ï½", "}")

    def _repl_prev_agent(m):
        agent_id = m.group(1)
        for cell in _get_prev_row_cells(ctx):
            if cell.get("agent_id") == agent_id:
                v = cell.get("message") or cell.get("raw") or {}
                return json_pretty(v) if isinstance(v, (dict, list)) else str(v)
        return f"(PrevStep.Agent:{agent_id} not found)"

    def _repl_prev_all(_m):
        return json_pretty(summarize_prev_row(ctx))

    def _repl_target_doc(_m):
        v = deep_get(ctx, "global_kv.target_doc")
        return v if isinstance(v, str) else (json_pretty(v) if v is not None else "")

    def _repl_judge(_m):
        v = find_judge_results(ctx)
        return json_pretty(v) if isinstance(v, (dict, list)) else (v or "(JudgeResult not found)")

    def _repl_prev_first_prompt(_m):
        txt = _get_prev_first_prompt_text(row_idx or 0)
        return txt or "(PrevStep.First.Prompt not found)"

    def _repl_prev_first_resp(_m):
        v = _get_prev_first_response(ctx)
        return json_pretty(v) if isinstance(v, (dict, list)) else (v or "(PrevStep.First.Response not found)")

    def _repl_context_path(m):
        path = normalize_context_path(m.group(1))
        v = deep_get(ctx, path)
        return json_pretty(v) if isinstance(v, (dict, list)) else (v if v is not None else f"(not found: Context.{path})")

    s = re.sub(r"\{PrevStep\.Agent:([A-Za-z0-9\-]+)\}", _repl_prev_agent, s)
    s = re.sub(r"\{PrevStep\.All\}", _repl_prev_all, s)
    s = re.sub(r"\{TargetDoc\}", _repl_target_doc, s)
    s = re.sub(r"\{JudgeResult\}", _repl_judge, s)
    s = re.sub(r"\{PrevStep\.First\.Prompt\}", _repl_prev_first_prompt, s)
    s = re.sub(r"\{PrevStep\.First\.Response\}", _repl_prev_first_resp, s)
    s = re.sub(r"\{Context\.([^\}]+)\}", _repl_context_path, s)
    return s


# ============ OpenAI ============
def get_openai_api_key() -> str:
    key = st.session_state.get("OPENAI_API_KEY") or os.environ.get("OPENAI_API_KEY") or os.environ.get("LLM_API_KEY")
    if not key:
        s_path = os.path.join(os.path.dirname(__file__), "secrets.toml")
        if os.path.exists(s_path):
            try:
                try:
                    import tomllib
                    with open(s_path, "rb") as fh:
                        data = tomllib.load(fh)
                except Exception:
                    try:
                        import toml as _toml
                        with open(s_path, "r", encoding="utf-8") as fh:
                            data = _toml.loads(fh.read())
                    except Exception:
                        data = {}
                key = key or data.get("LLM_API_KEY") or data.get("OPENAI_API_KEY")
            except Exception:
                key = key
    if key:
        try:
            st.session_state.OPENAI_API_KEY = key
        except Exception:
            pass
    if not key:
        raise RuntimeError("OPENAI_API_KEY ãŒæœªè¨­å®šã§ã™ï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼ã§è¨­å®šã¾ãŸã¯ secrets.toml ã« LLM_API_KEY ã‚’è¨­å®šã—ã¦ãã ã•ã„ï¼‰")
    return key

def call_llm(messages: List[Dict[str, str]], model: str, temperature: float, max_tokens: int, seed: Optional[int]) -> str:
    import openai
    key = get_openai_api_key()
    os.environ.setdefault("OPENAI_API_KEY", key)
    params = {"model": model, "temperature": float(temperature), "max_tokens": int(max_tokens)}
    if seed is not None:
        params["seed"] = int(seed)
    last_exc = None
    OpenAIClient = getattr(openai, "OpenAI", None)
    if OpenAIClient:
        try:
            try:
                client = OpenAIClient(api_key=key) if callable(OpenAIClient) else OpenAIClient()
            except Exception:
                client = OpenAIClient()
            try:
                chat = getattr(client, "chat", None)
                if chat and hasattr(chat, "completions"):
                    resp = chat.completions.create(messages=messages, **params)
                else:
                    responses = getattr(client, "responses", None)
                    if responses and hasattr(responses, "create"):
                        resp = responses.create(messages=messages, **params)
                    else:
                        resp = None
                if resp is not None:
                    try:
                        choice = resp.choices[0]
                        content = None
                        if hasattr(choice, "message"):
                            msg = choice.message
                            content = getattr(msg, "content", None)
                        elif isinstance(choice, dict):
                            msg = choice.get("message")
                            if isinstance(msg, dict):
                                content = msg.get("content")
                            else:
                                content = choice.get("text") or choice.get("content")
                        return str(content) if content is not None else str(resp)
                    except Exception as e:
                        last_exc = e
            except Exception as e:
                last_exc = e
        except Exception as e:
            last_exc = e
    try:
        openai.api_key = key
        resp = openai.ChatCompletion.create(model=model, messages=messages, temperature=float(temperature), max_tokens=int(max_tokens))
        try:
            return resp.choices[0].message["content"]
        except Exception:
            try:
                return resp.choices[0].text
            except Exception:
                return str(resp)
    except Exception as e:
        last_exc = e
    if last_exc:
        raise last_exc
    raise RuntimeError("openai client not available")


# ============ ãƒ‡ãƒ¼ã‚¿æ§‹é€  ============
@dataclass
class Agent:
    id: str
    name: str = "Agent"
    user_prompt: str = ""
    model: str = "gpt-4o-mini"
    temperature: float = 0.3
    max_tokens: int = 1200
    seed: Optional[int] = None
    enabled: bool = True

    history: List[Dict[str, str]] = field(default_factory=list)
    last_raw: str = ""
    last_json: Any = None

def new_agent(name: str = "Agent") -> Agent:
    return Agent(id=str(uuid.uuid4())[:8], name=name)


# ============ ã‚¢ãƒ—ãƒªçŠ¶æ…‹åˆæœŸåŒ– ============
def ensure_state():
    if "OPENAI_API_KEY" not in st.session_state:
        st.session_state.OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY", "")
    if "grid" not in st.session_state:
        st.session_state.grid = [[new_agent("Ingestor"), new_agent("Editor"), new_agent("Completer"), new_agent("Optimizer")]]
    if "current_row" not in st.session_state:
        st.session_state.current_row = 0
    if "loop_index" not in st.session_state:
        st.session_state.loop_index = 0
    if "current_loop_steps" not in st.session_state:
        st.session_state.current_loop_steps = []
    if "history_loops" not in st.session_state:
        st.session_state.history_loops = []
    if "view" not in st.session_state:
        st.session_state.view = "main"
    if "global_kv" not in st.session_state:
        base_doc = (
            "# ã‚¿ã‚¤ãƒˆãƒ«\n\n"
            "## æ¦‚è¦\n\n(ã“ã“ã«æ¦‚è¦)\n\n"
            "## å‰ææ¡ä»¶\n\n- \n\n"
            "## ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—\n\n- \n\n"
            "## æ‰‹é †\n\n"
            "### ã‚¹ãƒ†ãƒƒãƒ—1\n\n(ã‚„ã‚‹ã“ã¨)\n\n"
            "### ã‚¹ãƒ†ãƒƒãƒ—2\n\n(ã‚„ã‚‹ã“ã¨)\n\n"
            "### ã‚¹ãƒ†ãƒƒãƒ—3\n\n(ã‚„ã‚‹ã“ã¨)\n\n"
            "## ã‚ˆãã‚ã‚‹ã‚¨ãƒ©ãƒ¼ã¨å¯¾å‡¦\n\n"
            "- ç—‡çŠ¶: \n  - åŸå› : \n  - å¯¾å‡¦: \n\n"
            "## ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹\n\n- \n\n"
            "## æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—\n\n- \n\n"
            "## å‚è€ƒè³‡æ–™\n\n- \n\n"
            "## ä»˜éŒ²\n\n- \n"
        )
        desired_outline_default = [
            "# ã‚¿ã‚¤ãƒˆãƒ«",
            "æ¦‚è¦",
            "å‰ææ¡ä»¶",
            "ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—",
            "æ‰‹é †",
            "ã‚ˆãã‚ã‚‹ã‚¨ãƒ©ãƒ¼ã¨å¯¾å‡¦",
            "ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹",
            "æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—",
            "å‚è€ƒè³‡æ–™",
            "ä»˜éŒ²",
        ]
        st.session_state.global_kv = {
            "doc_title": "ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæ–‡æ›¸",
            "target_doc": base_doc,
            "doc_index": compute_doc_index(base_doc),
            "sources_word": [],
            "sources_excel": [],
            "sources_csv": [],
            "sources_text": [],
            "sources_web": [],
            "desired_outline": desired_outline_default,
        }
    if "defaults" not in st.session_state:
        st.session_state.defaults = {
            "model": "gpt-4o-mini",
            "temperature": 0.3,
            "max_tokens": 1200,
            "seed": None,
            "columns_per_row": 3,
        }
    if "ui_target_agent_id" not in st.session_state:
        st.session_state.ui_target_agent_id = None
    # éè¡¨ç¤ºã«ã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆIDï¼ˆæŒ‡å®šãŒã‚ã‚Œã°ï¼‰
    if "hidden_agent_ids" not in st.session_state:
        st.session_state.hidden_agent_ids = ["26bd9a2b"]  # æŒ‡å®šãŒã‚ã‚Œã°ã“ã“ã«åˆ—æŒ™

ensure_state()


# ============ Context æ§‹ç¯‰ ============
def build_indexed_response_current(row_idx: int) -> Dict[str, List[Dict[str, Any]]]:
    mapping: Dict[str, List[Dict[str, Any]]] = {}
    for abs_row in range(0, row_idx):
        rel = abs_row - row_idx
        row = st.session_state.grid[abs_row]
        cells: List[Dict[str, Any]] = []
        for c, agent in enumerate(row):
            last_user = None
            try:
                for h in reversed(agent.history):
                    if h.get("role") == "user":
                        last_user = h.get("content")
                        break
            except Exception:
                last_user = None
            cells.append({
                "message": agent.last_json,
                "raw": agent.last_raw or None,
                "agent_id": agent.id,
                "name": agent.name,
                "row": abs_row,
                "col": c,
                "prompt": last_user,
            })
        mapping[str(rel)] = cells
    return mapping

def build_context_for_row(row_idx: int) -> Dict[str, Any]:
    resp_cur = build_indexed_response_current(row_idx)
    prompt_map: Dict[str, List[Optional[str]]] = {}
    resp_only_map: Dict[str, List[Optional[str]]] = {}
    for k, cells in (resp_cur or {}).items():
        if isinstance(cells, list):
            prompt_map[k] = [(cell.get("prompt") if isinstance(cell, dict) else None) for cell in cells]
            resp_only_map[k] = [(cell.get("raw") if isinstance(cell, dict) else None) for cell in cells]
        else:
            prompt_map[k] = []
            resp_only_map[k] = []
    return {
        "loop_index": st.session_state.loop_index,
        "current_row": row_idx,
        "response": {"0": resp_cur},
        "resp": resp_cur,
        "Prompt": prompt_map,
        "RespOnly": resp_only_map,
        "System": SCHEMA_ENFORCER,
        "global_kv": st.session_state.global_kv,
    }


# ============ Workflow ä¿å­˜/èª­è¾¼ ============
def serialize_workflow() -> str:
    grid_dump: List[List[Dict[str, Any]]] = []
    for row in st.session_state.grid:
        row_dump = []
        for ag in row:
            row_dump.append({
                "id": ag.id,
                "name": ag.name,
                "user_prompt": ag.user_prompt,
                "model": ag.model,
                "temperature": ag.temperature,
                "max_tokens": ag.max_tokens,
                "seed": ag.seed,
                "enabled": ag.enabled,
            })
        row_dump.append
        grid_dump.append(row_dump)
    data = {
        "version": 2,
        "defaults": st.session_state.defaults,
        "global_kv": st.session_state.global_kv,
        "grid": grid_dump,
        "current_row": st.session_state.current_row,
        "loop_index": st.session_state.loop_index,
    }
    return json.dumps(data, ensure_ascii=False, indent=2)

def deserialize_workflow(text: str):
    try:
        data = json.loads(text)
    except Exception as e:
        st.error(f"èª­è¾¼å¤±æ•—: {e}")
        return
    try:
        st.session_state.defaults = data.get("defaults", st.session_state.defaults)
        st.session_state.global_kv = data.get("global_kv", st.session_state.global_kv)
        grid_dump = data.get("grid", [])
        grid: List[List[Agent]] = []
        for row in grid_dump:
            row_agents: List[Agent] = []
            for a in row:
                ag = Agent(
                    id=a.get("id") or str(uuid.uuid4())[:8],
                    name=a.get("name", "Agent"),
                    user_prompt=a.get("user_prompt", ""),
                    model=a.get("model", st.session_state.defaults.get("model", "gpt-4o-mini")),
                    temperature=a.get("temperature", 0.3),
                    max_tokens=a.get("max_tokens", 1200),
                    seed=a.get("seed"),
                    enabled=a.get("enabled", True),
                )
                row_agents.append(ag)
            grid.append(row_agents)
        if grid:
            st.session_state.grid = grid
        st.session_state.current_row = int(data.get("current_row", 0))
        st.session_state.loop_index = int(data.get("loop_index", 0))
        st.success("ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
    except Exception as e:
        st.error(f"ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å¤‰æ›å¤±æ•—: {e}")


# ============ Agent å®Ÿè¡Œ ============
def run_agent(agent: Agent, row_idx: int) -> Agent:
    if not agent.enabled:
        return agent

    ctx = build_context_for_row(row_idx)
    expanded_instr = expand_prompt_macros(agent.user_prompt or "", ctx, row_idx=row_idx)

    messages = [{"role": "system", "content": SCHEMA_ENFORCER}] + agent.history[-20:] + [{"role": "user", "content": expanded_instr}]

    model = agent.model or st.session_state.defaults["model"]
    temperature = agent.temperature if agent.temperature is not None else st.session_state.defaults["temperature"]
    max_tokens = int(agent.max_tokens or st.session_state.defaults["max_tokens"])
    seed = agent.seed if agent.seed is not None else st.session_state.defaults["seed"]

    try:
        raw = call_llm(messages, model=model, temperature=temperature, max_tokens=max_tokens, seed=seed)
    except Exception as e:
        raw = json.dumps({"ok": False, "message": {"error": f"LLM error: {e}"}, "kv_patch": {}, "meta": {"event": "error"}}, ensure_ascii=False)

    parsed = force_parse_json(raw)
    unified = normalize_unified(parsed)

    try:
        if "meta" not in unified or not isinstance(unified["meta"], dict):
            unified["meta"] = {}
        if "event" not in unified["meta"]:
            unified["meta"]["event"] = "success" if unified.get("ok") else "error"
    except Exception:
        pass

    agent.history.append({"role": "user", "content": expanded_instr})
    agent.history.append({"role": "assistant", "content": raw})
    agent.history = agent.history[-40:]

    agent.last_raw = raw
    agent.last_json = unified
    return agent


# ============ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œ ============
def _apply_prompt_patch(prompt_patch: Dict[str, Any], current_row: int):
    if not isinstance(prompt_patch, dict):
        return
    grid = st.session_state.grid
    for off_key, col_map in prompt_patch.items():
        try:
            off = int(off_key)
        except Exception:
            continue
        tgt_row = current_row + off
        if not (0 <= tgt_row < len(grid)):
            continue
        if not isinstance(col_map, dict):
            continue
        for c_key, new_prompt in col_map.items():
            try:
                cidx = int(c_key)
            except Exception:
                continue
            if not (0 <= cidx < len(grid[tgt_row])):
                continue
            if not isinstance(new_prompt, str):
                continue
            ag = grid[tgt_row][cidx]
            ag.user_prompt = new_prompt
            st.session_state.grid[tgt_row][cidx] = ag
            try:
                pk = f"det_prompt_{ag.id}_pending"
                st.session_state[pk] = new_prompt
                safe_rerun()
            except Exception:
                pass

def _apply_kv_patch(patch: Dict[str, Any]):
    if not isinstance(patch, dict):
        return
    for k, v in patch.items():
        if k == "Prompt":
            continue
        if k == "target_doc" and isinstance(v, str):
            st.session_state.global_kv["target_doc"] = v
            try:
                st.session_state.global_kv["doc_index"] = compute_doc_index(v)
            except Exception:
                pass
        else:
            st.session_state.global_kv[k] = v

def _parse_next_spec(next_spec: Any, current_row: int) -> Optional[Any]:
    if not next_spec:
        return None
    if isinstance(next_spec, dict):
        if next_spec.get("end"):
            return "end"
        if "row" in next_spec:
            r = next_spec["row"]
            if isinstance(r, str) and (r.startswith("+") or r.startswith("-")):
                try:
                    return current_row + int(r)
                except Exception:
                    return None
            if isinstance(r, int):
                return r
    if isinstance(next_spec, str):
        if next_spec.lower() in ("end", "finish"):
            return "end"
        if next_spec.startswith("+") or next_spec.startswith("-"):
            try:
                return current_row + int(next_spec)
            except Exception:
                return None
        try:
            return int(next_spec)
        except Exception:
            return None
    return None

def step_execute(row_idx: int):
    if row_idx >= len(st.session_state.grid):
        return
    row = st.session_state.grid[row_idx]
    step_result: Dict[str, Any] = {}

    for col, agent in enumerate(row):
        if not agent.enabled:
            continue
        updated = run_agent(agent, row_idx)
        st.session_state.grid[row_idx][col] = updated
        step_result[updated.id] = updated.last_json
        if isinstance(updated.last_json, dict):
            patch = updated.last_json.get("kv_patch") or {}
            _apply_kv_patch(patch)
            if isinstance(patch.get("Prompt"), dict):
                _apply_prompt_patch(patch.get("Prompt") or {}, row_idx)
            try:
                if isinstance(patch.get("target_doc"), str):
                    updated.last_json.setdefault("kv_patch", {})["target_doc"] = ""
                if isinstance(patch.get("Prompt"), dict):
                    updated.last_json.setdefault("kv_patch", {})["Prompt"] = {}
                st.session_state.grid[row_idx][col] = updated
            except Exception:
                pass

    if len(st.session_state.current_loop_steps) == row_idx:
        st.session_state.current_loop_steps.append(step_result)
    else:
        while len(st.session_state.current_loop_steps) < row_idx:
            st.session_state.current_loop_steps.append({})
        st.session_state.current_loop_steps.append(step_result)

    next_ptr = None
    try:
        for ag in st.session_state.grid[row_idx]:
            uni = ag.last_json if isinstance(ag.last_json, dict) else None
            if not uni:
                continue
            meta = uni.get("meta") or {}
            cand = _parse_next_spec(meta.get("next"), row_idx)
            if cand is not None:
                next_ptr = cand
                break
    except Exception:
        next_ptr = None

    if next_ptr == "end":
        st.session_state.history_loops.append({"loop_index": st.session_state.loop_index, "steps": st.session_state.current_loop_steps})
        st.session_state.loop_index += 1
        st.session_state.current_loop_steps = []
        st.session_state.current_row = 0
        return

    if isinstance(next_ptr, int) and 0 <= next_ptr < len(st.session_state.grid):
        st.session_state.current_row = next_ptr
        return

    if row_idx == len(st.session_state.grid) - 1:
        st.session_state.history_loops.append({"loop_index": st.session_state.loop_index, "steps": st.session_state.current_loop_steps})
        st.session_state.loop_index += 1
        st.session_state.current_loop_steps = []
        st.session_state.current_row = 0
    else:
        st.session_state.current_row = row_idx + 1

def run_one_step():
    if not st.session_state.grid or not st.session_state.grid[0]:
        st.warning("ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒã‚ã‚Šã¾ã›ã‚“")
        return
    step_execute(st.session_state.current_row)

def run_to_end():
    if not st.session_state.grid or not st.session_state.grid[0]:
        st.warning("ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒã‚ã‚Šã¾ã›ã‚“")
        return
    while True:
        row_idx = st.session_state.current_row
        step_execute(row_idx)
        if st.session_state.current_row == 0 and row_idx == len(st.session_state.grid) - 1:
            break

def run_to_end_times(n: int):
    n = max(1, int(n or 1))
    for _ in range(n):
        run_to_end()


# ============ ç”»é¢é·ç§» / æ¤œç´¢ ============
def go_detail(agent_id: str):
    st.session_state.ui_target_agent_id = agent_id
    st.session_state.view = "detail"
    safe_rerun()

def go_main():
    st.session_state.view = "main"
    st.session_state.ui_target_agent_id = None
    safe_rerun()

def find_agent_pos(agent_id: str):
    for r, row in enumerate(st.session_state.grid):
        for c, agent in enumerate(row):
            if agent.id == agent_id:
                return (r, c, agent)
    return None


# ============ å–è¾¼ï¼ˆWord/Excel/CSV/Text/Webï¼‰ ============
def read_word_to_markdown(file) -> str:
    tmp_path = None
    out_md_path = None
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".docx") as tmp:
            data = file.read()
            tmp.write(data)
            tmp_path = tmp.name
        if pypandoc is not None:
            try:
                try:
                    pypandoc.get_pandoc_version()
                except OSError:
                    try:
                        pypandoc.download_pandoc()
                    except Exception:
                        pass
                out_md_path = tmp_path + '.md'
                pypandoc.convert_file(tmp_path, 'md', outputfile=out_md_path, extra_args=['--standalone'])
                with open(out_md_path, 'r', encoding='utf-8') as fh:
                    md = fh.read()
                md = re.sub(r" {2,}", " ", md)
                return md
            except Exception:
                pass
        if Document is not None:
            try:
                doc = Document(tmp_path)
                parts = []
                for p in doc.paragraphs:
                    txt = (p.text or "").strip()
                    if txt:
                        parts.append(txt)
                for tbl in doc.tables:
                    for row in tbl.rows:
                        cells = [" " + (c.text or "").replace("\n", " ").strip() + " " for c in row.cells]
                        parts.append("|" + "|".join(cells) + "|")
                md = "\n\n".join(parts)
                md = re.sub(r" {2,}", " ", md)
                return md
            except Exception:
                pass
        try:
            sample = data[:2000] if isinstance(data, (bytes, bytearray)) else str(data)[:2000]
            return f"```\n{sample}\n```\n(æ³¨: docx è§£æã«å¤±æ•—)"
        except Exception:
            return "(docx ã®è§£æã«å¤±æ•—)"
    finally:
        try:
            if tmp_path and os.path.exists(tmp_path):
                os.remove(tmp_path)
        except Exception:
            pass
        try:
            if out_md_path and os.path.exists(out_md_path):
                os.remove(out_md_path)
        except Exception:
            pass

def df_to_markdown_or_csv(df) -> str:
    if df is None:
        return ""
    try:
        return df.to_markdown(index=False)
    except Exception:
        return df.to_csv(index=False)

def read_excel_to_markdown(file) -> str:
    if pd is None:
        return "(pandas ãŒç„¡ã„ãŸã‚Excelã‚’å‡¦ç†ã§ãã¾ã›ã‚“)"
    tmp_path = None
    try:
        suffix = Path(getattr(file, 'name', '') or '').suffix.lower() or '.xlsx'
        with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
            tmp.write(file.read())
            tmp_path = tmp.name
        engine = None
        if suffix in ('.xlsx', '.xlsm'):
            engine = 'openpyxl'
        elif suffix == '.xls':
            engine = 'xlrd'
        try:
            if engine:
                xls = pd.ExcelFile(tmp_path, engine=engine)
            else:
                xls = pd.ExcelFile(tmp_path)
        except Exception:
            xls = pd.ExcelFile(tmp_path)
        out_parts = []
        for sheet in xls.sheet_names:
            try:
                df = xls.parse(sheet, header=None).fillna("")
                try:
                    md = df.to_markdown(index=False)
                except Exception:
                    md = df.to_csv(index=False)
                md = re.sub(r" {2,}", " ", md)
                out_parts.append(f"## {sheet}\n\n{md}")
            except Exception:
                out_parts.append(f"## {sheet}\n\n(ã‚·ãƒ¼ãƒˆã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ)")
        return "\n\n".join(out_parts)
    except Exception as e:
        return f"(Excel è§£æå¤±æ•—: {e})"
    finally:
        try:
            if tmp_path and os.path.exists(tmp_path):
                os.remove(tmp_path)
        except Exception:
            pass

def read_csv_to_markdown(file) -> str:
    if pd is None:
        try:
            data = file.read().decode("utf-8", errors="ignore")
            return f"```\n{data}\n```"
        except Exception as e:
            return f"(CSV èª­ã¿è¾¼ã¿å¤±æ•—: {e})"
    try:
        df = pd.read_csv(file)
        return df_to_markdown_or_csv(df)
    except Exception as e:
        return f"(CSV è§£æå¤±æ•—: {e})"

def read_text(file) -> str:
    try:
        return file.read().decode("utf-8", errors="ignore")
    except Exception:
        try:
            return file.read().decode("cp932", errors="ignore")
        except Exception as e:
            return f"(ãƒ†ã‚­ã‚¹ãƒˆèª­è¾¼å¤±æ•—: {e})"

def html_to_markdown(html: str) -> str:
    if not isinstance(html, str):
        html = str(html or "")
    if _h2t:
        conv = _h2t.HTML2Text()
        conv.ignore_links = False
        conv.body_width = 0
        md = conv.handle(html)
    else:
        md = re.sub(r"<[^>]+>", "", html)
    md = re.sub(r"\n{3,}", "\n\n", md).strip()
    return md

def read_web_to_markdown(url: str) -> Dict[str, Any]:
    """
    æŒ‡å®šURLã‹ã‚‰æœ¬æ–‡ã‚’æŠ½å‡ºã—ã¦Markdownæ–‡å­—åˆ—ã‚’è¿”ã™
    è¿”å´: { 'ok': bool, 'title': str, 'url': str, 'content_md': str, 'fetched_at': str, 'error': str|None }
    """
    from datetime import datetime, timezone

    if not url or not isinstance(url, str):
        return {"ok": False, "title": "", "url": url, "content_md": "", "fetched_at": "", "error": "invalid_url"}

    title = ""
    md = ""
    err = None

    try:
        # 1) trafilatura ã‚’å„ªå…ˆ
        if trafilatura is not None:
            downloaded = trafilatura.fetch_url(url)
            if downloaded:
                extracted = trafilatura.extract(
                    downloaded,
                    include_formatting=True,
                    include_links=True,
                    favor_recall=True,
                )
                if extracted:
                    md = extracted
                    lines = [ln.strip() for ln in md.splitlines() if ln.strip()]
                    if lines:
                        title = lines[0].lstrip("# ").strip()[:80]

        # 2) readability-lxml
        if not md and (requests is not None) and (ReadabilityDocument is not None):
            headers = {"User-Agent": "Mozilla/5.0 (compatible; ContentIngestor/1.0; +https://example.com)"}
            r = requests.get(url, headers=headers, timeout=20)
            r.raise_for_status()
            html = r.text
            doc = ReadabilityDocument(html)
            title = (doc.short_title() or "").strip()[:80] or title
            cleaned_html = doc.summary(html_partial=True)
            md = html_to_markdown(cleaned_html)

        # 3) BeautifulSoup ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        if not md and (requests is not None) and (BeautifulSoup is not None):
            headers = {"User-Agent": "Mozilla/5.0 (compatible; ContentIngestor/1.0; +https://example.com)"}
            r = requests.get(url, headers=headers, timeout=20)
            r.raise_for_status()
            html = r.text
            soup = BeautifulSoup(html, "html.parser")
            # ãƒã‚¤ã‚ºé™¤å»
            for tag in soup(["script", "style", "noscript", "svg", "canvas", "form", "iframe"]):
                tag.decompose()
            for tag in soup.find_all(["header", "footer", "nav", "aside"]):
                tag.decompose()
            # ã‚¿ã‚¤ãƒˆãƒ«
            if soup.title and soup.title.string:
                title = (soup.title.string or "").strip()[:80] or title
            # æœ¬æ–‡å€™è£œ
            main = soup.find(["main", "article"]) or soup.body or soup
            cleaned_html = str(main)
            md = html_to_markdown(cleaned_html)

        # è»½ã„ãƒã‚¤ã‚ºæŠ‘åˆ¶
        if md:
            noise_patterns = [
                r"^ã“ã®è¨˜äº‹ã‚’ã‚·ã‚§ã‚¢", r"^é–¢é€£è¨˜äº‹", r"^åºƒå‘Š", r"^ã‚¹ãƒãƒ³ã‚µãƒ¼", r"^åŒæ„ã—ã¾ã™", r"^Cookie",
            ]
            lines = md.splitlines()
            cleaned = []
            for ln in lines:
                if any(re.search(pat, ln, re.I) for pat in noise_patterns):
                    continue
                cleaned.append(ln)
            md = "\n".join(cleaned).strip()

        if not md:
            err = "extract_failed"

    except Exception as e:
        err = f"{e}"

    return {
        "ok": bool(md),
        "title": title or "(no title)",
        "url": url,
        "content_md": md or "",
        "fetched_at": datetime.now(timezone.utc).isoformat(),
        "error": err,
    }


# ============ UI: Sidebarï¼ˆä¿å­˜/èª­è¾¼/è¨­å®š/å–è¾¼/å®Ÿè¡Œï¼‰ ============
def apply_default_knowledge_flow():
    st.session_state.grid = [[
        Agent(id=str(uuid.uuid4())[:8], name="Ingestor", user_prompt=(
            "ã‚ãªãŸã¯æƒ…å ±ã‚¤ãƒ³ã‚¸ã‚§ã‚¹ãƒˆæ‹…å½“ã§ã™ã€‚\n"
            "ç›®çš„:\n"
            "- å–ã‚Šè¾¼ã¿ã‚½ãƒ¼ã‚¹ï¼ˆWord/Excel/CSV/Text/Webï¼‰ã‚’æ­£è¦åŒ–ã—ã€æ—¢å­˜ã®æœ¬æ–‡ã«çµ±åˆã—ã¾ã™ã€‚\n"
            "- æœ¬æ–‡ã‚’ã€Œãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«å‘ã‘Markdownã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³ã€ã«æ²¿ã£ã¦æ§‹æˆæ•´ç†ã—ã¾ã™ã€‚\n"
            "å…¥åŠ›:\n"
            "- æœ¬æ–‡ï¼ˆç¾çŠ¶ï¼‰: {Context.global_kv.target_doc}\n"
            "- å–ã‚Šè¾¼ã¿ï¼ˆWordï¼‰: {Context.global_kv.sources_word}\n"
            "- å–ã‚Šè¾¼ã¿ï¼ˆExcelï¼‰: {Context.global_kv.sources_excel}\n"
            "- å–ã‚Šè¾¼ã¿ï¼ˆCSVï¼‰: {Context.global_kv.sources_csv}\n"
            "- å–ã‚Šè¾¼ã¿ï¼ˆTextï¼‰: {Context.global_kv.sources_text}\n"
            "- å–ã‚Šè¾¼ã¿ï¼ˆWebï¼‰: {Context.global_kv.sources_web}\n"
            "- æœ›ã¾ã—ã„ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³ï¼ˆä»»æ„ï¼‰: {Context.global_kv.desired_outline}\n"
            "ã‚„ã‚‹ã“ã¨:\n"
            "- ã‚½ãƒ¼ã‚¹ã‚’èª­ã¿ã€é‡è¤‡ãƒ»ãƒã‚¤ã‚ºã‚’é™¤å»ã—ã¦è¦ç‚¹ã‚’Markdownã«æ­£è¦åŒ–ã€‚\n"
            "- desired_outline ãŒç©ºãªã‚‰ã€ä»¥ä¸‹ã®æ—¢å®šã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³ã§æœ¬æ–‡ã‚’å†æ§‹æˆ:\n"
            "  ã€Œã‚¿ã‚¤ãƒˆãƒ«/æ¦‚è¦/å‰ææ¡ä»¶/ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—/æ‰‹é †(ã‚¹ãƒ†ãƒƒãƒ—1..)/ã‚ˆãã‚ã‚‹ã‚¨ãƒ©ãƒ¼ã¨å¯¾å‡¦/ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹/æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—/å‚è€ƒè³‡æ–™/ä»˜éŒ²ã€\n"
            "- æ—¢å­˜æœ¬æ–‡ã®æœ‰ç”¨éƒ¨ã¯ä¿æŒã—ã€å¿…è¦ã«å¿œã˜ã¦ç¯€ï¼ˆ## è¦‹å‡ºã—ï¼‰ã‚’æ–°è¨­ã—ã¦çµ±åˆã€‚\n"
            "- æ ¹æ‹ ã¯å–ã‚Šè¾¼ã¿ã‚½ãƒ¼ã‚¹ã‹ã‚‰ã®ã¿ã€‚ä¸æ˜ç‚¹ã¯æ¨æ¸¬ã›ãšã€ŒTODO: ï½ã‚’ç¢ºèªã€ã¨æ˜ç¤ºã€‚\n"
            "- å‚è€ƒãƒªãƒ³ã‚¯ã¯sources_webã‹ã‚‰ã®ã¿å¼•ç”¨ï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆï¼‰ã€‚å‡ºå…¸ã¯ã€Œå‚è€ƒè³‡æ–™ã€ç¯€ã«ç®‡æ¡æ›¸ãã§é›†ç´„ã€‚\n"
            "- æ–‡ä½“ã¯ç°¡æ½”ãƒ»æ‰‹é †ä¸­å¿ƒã€‚è¦‹å‡ºã—ãƒ»ç®‡æ¡æ›¸ããƒ»ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ï¼ˆå¿…è¦æ™‚ï¼‰ã®æ•´å½¢ã€‚\n"
            "- ã‚¿ã‚¤ãƒˆãƒ«æœªè¨­å®šãªã‚‰é©åˆ‡ã«è£œã†ã€‚\n"
            "- tokenåˆ¶é™å†…ã§æœ€é‡è¦é …ç›®ã‚’å„ªå…ˆçµ±åˆã€‚\n"
            "å¤±æ•—æ™‚ã®æŒ¯ã‚‹èˆã„:\n"
            "- æ–°è¦ã®æœ‰ç›Šæƒ…å ±ãŒç„¡ã„å ´åˆã¯æœ¬æ–‡ã‚’å¤§ããå¤‰æ›´ã›ãšã€notesã«ç†ç”±ã‚’è¨˜è¿°ã€‚\n"
            "å‡ºåŠ›ã¯JSONã®ã¿ï¼ˆå‰ç½®ãã‚„ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ç¦æ­¢ï¼‰:\n"
            "{\n"
            "  \"ok\": true,\n"
            "  \"message\": {\n"
            "    \"type\": \"ingest\",\n"
            "    \"notes\": \"(çµ±åˆãƒ¡ãƒ¢: ä½•ã‚’å–ã‚Šè¾¼ã¿ã€ä½•ã‚’æ®ãˆç½®ã„ãŸã‹ã€‚TODOã‚‚æ˜è¨˜)\",\n"
            "    \"changes\": [\"(è¿½åŠ /ä¿®æ­£ã—ãŸä¸»ãªè¦‹å‡ºã—ã‚„ç¯€)\"]\n"
            "  },\n"
            "  \"kv_patch\": {\"target_doc\": \"(çµ±åˆå¾Œã®æœ¬æ–‡Markdownå…¨æ–‡: ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³ã«æº–æ‹ )\"},\n"
            "  \"meta\": {}\n"
            "}\n"
        )),
        Agent(id=str(uuid.uuid4())[:8], name="Editor", user_prompt=(
            "ã‚ãªãŸã¯æœ¬æ–‡ç·¨é›†æ‹…å½“ã§ã™ã€‚\n"
            "ç›®çš„:\n"
            "- æœ¬æ–‡ã‚’èª­ã¿ã‚„ã™ãå†ç·¨é›†ã—ã€ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«å‘ã‘Markdownã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³ã«å®Œå…¨æº–æ‹ ã•ã›ã¾ã™ã€‚\n"
            "å…¥åŠ›:\n"
            "- ç¾åœ¨ã®æœ¬æ–‡: {Context.global_kv.target_doc}\n"
            "- æœ¬æ–‡ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: {Context.global_kv.doc_index}\n"
            "- ç›´å‰STEPã®å‡ºåŠ›: {Context.resp[\"-1\"]}\n"
            "- æœ›ã¾ã—ã„ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³ï¼ˆä»»æ„ï¼‰: {Context.global_kv.desired_outline}\n"
            "ã‚„ã‚‹ã“ã¨:\n"
            "- desired_outline ãŒã‚ã‚Œã°ãã‚Œã«å³å¯†ã«åˆã‚ã›ã€ç„¡ã‘ã‚Œã°æ—¢å®šã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³ã«æº–æ‹ ã€‚\n"
            "- ç¯€æ§‹æˆã®é‡è¤‡ã‚’è§£æ¶ˆã€è¦‹å‡ºã—ç²’åº¦ã‚’çµ±ä¸€ã€ã‚¹ãƒ†ãƒƒãƒ—åã‚’å‹•è©ã‹ã‚‰å§‹ã¾ã‚‹å½¢ã«æ•´ç†ã€‚\n"
            "- ç”¨èªã‚’çµ±ä¸€ã€å†—é•·è¡¨ç¾ã‚„æ›–æ˜§è¡¨ç¾ã‚’å‰Šæ¸›ã€‚ç®‡æ¡æ›¸ããƒ»è¡¨ãƒ»ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’é©åˆ‡ã«ä½¿ç”¨ã€‚\n"
            "- ã€Œã‚ˆãã‚ã‚‹ã‚¨ãƒ©ãƒ¼ã¨å¯¾å‡¦ã€ã¯ ç—‡çŠ¶â†’åŸå› â†’å¯¾å‡¦ ã®é †ã§æœ€å°ãƒ†ãƒ³ãƒ—ãƒ¬ã«æ•´å½¢ã€‚\n"
            "- å‡ºå…¸ã‚„URLã¯ã€Œå‚è€ƒè³‡æ–™ã€ç¯€ã«é›†ç´„ã—ã€æœ¬æ–‡ä¸­ã¯æœ€å°é™ã®å‚ç…§ã€‚\n"
            "- é‡è¦æƒ…å ±ã¯æ®‹ã—ã€é‡è¤‡ã®ã¿çµ±åˆãƒ»çœç•¥ã€‚\n"
            "å‡ºåŠ›ã¯JSONã®ã¿ï¼ˆå‰ç½®ãã‚„ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ç¦æ­¢ï¼‰:\n"
            "{\n"
            "  \"ok\": true,\n"
            "  \"message\": {\"type\": \"commit\", \"summary\": \"(å¤‰æ›´ç‚¹ã®è¦ç´„: æ§‹æˆå¤‰æ›´ã€è¡¨ç¾çµ±ä¸€ã€é‡è¤‡è§£æ¶ˆãªã©)\"},\n"
            "  \"kv_patch\": {\"target_doc\": \"(ç·¨é›†å¾Œã®æœ¬æ–‡å…¨ä½“: ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³æº–æ‹ ãƒ»èª­ã¿ã‚„ã™ã•æ”¹å–„æ¸ˆã¿)\"},\n"
            "  \"meta\": {}\n"
            "}\n"
        )),
        Agent(id=str(uuid.uuid4())[:8], name="Completer", user_prompt=(
            "ã‚ãªãŸã¯æ§‹æˆè£œå®Œæ‹…å½“ã§ã™ã€‚\n"
            "ç›®çš„:\n"
            "- æŠœã‘ã¦ã„ã‚‹ç¯€ã‚„è¨˜è¿°ã‚’æ¤œå‡ºã—ã€å¿…è¦æœ€å°é™ã®å†…å®¹ã‚’è¿½åŠ ã—ã¦å®Œå…¨æ€§ã‚’é«˜ã‚ã¾ã™ã€‚\n"
            "å…¥åŠ›:\n"
            "- æœ¬æ–‡ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: {Context.global_kv.doc_index}\n"
            "- æœ¬æ–‡: {Context.global_kv.target_doc}\n"
            "- æœ›ã¾ã—ã„ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³ï¼ˆä»»æ„ï¼‰: {Context.global_kv.desired_outline}\n"
            "ã‚„ã‚‹ã“ã¨:\n"
            "- desired_outline ã¾ãŸã¯æ—¢å®šã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³ã¨ç…§åˆã—ã€æ¬ è½ç¯€ã‚’ç‰¹å®šã€‚\n"
            "- ã€Œå‰ææ¡ä»¶ã€ã€Œç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã€ã€Œæ‰‹é †ã€ã«å¿…é ˆã®æŠœã‘ãŒã‚ã‚Œã°å„ªå…ˆè£œå®Œã€‚\n"
            "- è£œå®Œã¯æœ€å°é™ã‹ã¤å®Ÿç”¨é‡è¦–ã€‚æ ¹æ‹ ä¸æ˜ã®äº‹é …ã¯ã€ŒTODO: è¦ç¢ºèªã€ã‚’æ˜è¨˜ã€‚\n"
            "- æ—¢å­˜è¨˜è¿°ã¨é‡è¤‡ã—ãªã„ã‚ˆã†ã«å·®åˆ†è¿½åŠ ã€‚å¤§å¹…æ›¸ãæ›ãˆã¯é¿ã‘ã‚‹ã€‚\n"
            "å‡ºåŠ›ã¯JSONã®ã¿ï¼ˆå‰ç½®ãã‚„ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ç¦æ­¢ï¼‰:\n"
            "{\n"
            "  \"ok\": true,\n"
            "  \"message\": {\"type\": \"complete\", \"added\": [\"(è¿½åŠ ã—ãŸè¦‹å‡ºã—ã‚„å°ç¯€)\"], \"notes\": \"(è£œå®Œæ–¹é‡ã‚„æœªè§£æ±ºTODO)\"},\n"
            "  \"kv_patch\": {\"target_doc\": \"(è£œå®Œå¾Œã®æœ¬æ–‡å…¨ä½“)\"},\n"
            "  \"meta\": {}\n"
            "}\n"
        )),
        Agent(id=str(uuid.uuid4())[:8], name="Optimizer", user_prompt=(
            "ã‚ãªãŸã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ”¹å–„æ‹…å½“ã§ã™ã€‚\n"
            "ç›®çš„:\n"
            "- ç¾åœ¨è¡Œã®ã€Œå·¦ã‹ã‚‰1ç•ªï¼Ingestorã€ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ã€å–ã‚Šè¾¼ã¿æ¼ã‚Œé˜²æ­¢ãƒ»ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³å¾¹åº•ãƒ»éæ¨æ¸¬æ–¹é‡ã®æ˜ç¢ºåŒ–ã®è¦³ç‚¹ã§æ”¹å–„ã—ã¦å³æ™‚æ›´æ–°ã—ã¾ã™ã€‚\n"
            "å…¥åŠ›:\n"
            "- ç›´å‰STEPã®å·¦ã‹ã‚‰1ç•ªã®å‡ºåŠ›è¦ç´„: {Context.resp[\"-1\"][0].message}\n"
            "- ã‚°ãƒ­ãƒ¼ãƒãƒ«æƒ…å ±ï¼ˆå–ã‚Šè¾¼ã¿ã‚½ãƒ¼ã‚¹ãƒ»ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³ï¼‰: {Context.global_kv}\n"
            "ãƒã‚§ãƒƒã‚¯é …ç›®:\n"
            "- sources_word / sources_excel / sources_csv / sources_text / sources_web ã‚’ã™ã¹ã¦å‚ç…§ã—ã¦ã„ã‚‹ã‹\n"
            "- desired_outline ã‚’è€ƒæ…®ï¼ˆç„¡ã„å ´åˆã¯æ—¢å®šã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³ã‚’æ˜ç¤ºï¼‰\n"
            "- æœ¬æ–‡ã‚’ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«å‘ã‘Markdownã§æ§‹æˆ\n"
            "- æœªçŸ¥ã¯TODOæ˜ç¤ºãƒ»å‡ºå…¸é›†ç´„ãƒ»tokené…æ…®ãƒ»JSONã®ã¿å‡ºåŠ›ï¼ˆã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ç¦æ­¢ï¼‰\n"
            "å‡ºåŠ›ã¯JSONã®ã¿ï¼ˆå‰ç½®ãã‚„ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ç¦æ­¢ï¼‰:\n"
            "{\n"
            "  \"ok\": true,\n"
            "  \"message\": {\"type\": \"prompt_update\", \"before\": \"(ç¾ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®è¦ç´„ã‚„æ”¹å–„è¦³ç‚¹)\", \"after\": \"(æ”¹å–„å¾Œãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå…¨æ–‡)\"},\n"
            "  \"kv_patch\": {\"Prompt\": {\"0\": {\"0\": \"(æ”¹å–„å¾Œãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå…¨æ–‡)\"}}},\n"
            "  \"meta\": {}\n"
            "}\n"
        )),
    ]]
    st.session_state.current_row = 0
    st.session_state.current_loop_steps = []
    st.success("ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒŠãƒ¬ãƒƒã‚¸ãƒ•ãƒ­ãƒ¼ã‚’é©ç”¨ã—ã¾ã—ãŸ")

with st.sidebar:
    st.header("è¨­å®š")
    st.session_state.OPENAI_API_KEY = st.text_input("OPENAI_API_KEY", value=st.session_state.get("OPENAI_API_KEY", ""), type="password")
    d = st.session_state.defaults
    d["model"] = st.text_input("Model", value=d.get("model", "gpt-4o-mini"))
    d["temperature"] = float(st.slider("temperature", 0.0, 2.0, float(d.get("temperature", 0.3)), 0.1))
    d["max_tokens"] = int(st.number_input("max_tokens", min_value=128, max_value=8192, value=int(d.get("max_tokens", 1200)), step=64))
    d["columns_per_row"] = int(st.number_input("è¡¨ç¤ºåˆ—æ•°", 1, 8, int(d.get("columns_per_row", 3)), 1))

    st.markdown("---")
    st.caption(f"Loop: {st.session_state.loop_index}")
    st.caption(f"Current Row: {st.session_state.current_row+1} / {len(st.session_state.grid)}")
    st.caption(f"Agents: {sum(len(r) for r in st.session_state.grid)}")

    st.markdown("---")
    if st.button("ğŸ“ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ•ãƒ­ãƒ¼é©ç”¨"):
        apply_default_knowledge_flow()
        safe_rerun()

    save_json = serialize_workflow()
    st.download_button("ğŸ’¾ ä¿å­˜", data=save_json, file_name="workflow.json", mime="application/json")
    up_flow = st.file_uploader("ğŸ“‚ èª­è¾¼ (JSON)", type=["json"], key="wf_upload")
    if up_flow is not None:
        try:
            text = up_flow.read().decode("utf-8")
            if st.button("èª­è¾¼ã‚’é©ç”¨"):
                deserialize_workflow(text)
                safe_rerun()
        except Exception as e:
            st.error(f"èª­è¾¼å¤±æ•—: {e}")

    st.markdown("---")
    # ãƒ•ã‚¡ã‚¤ãƒ«å–è¾¼ï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ç§»å‹•ï¼‰
    st.subheader("ãƒ•ã‚¡ã‚¤ãƒ«å–è¾¼")
    with st.expander("Word (.docx)"):
        wfile = st.file_uploader("Word ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ", type=["docx"], key="up_word")
        if wfile is not None:
            md = read_word_to_markdown(wfile)
            st.text_area("ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆMarkdownç›¸å½“ï¼‰", value=md, height=160, key="preview_word")
            if st.button("sources_word ã«ä¿å­˜", key="save_word"):
                st.session_state.global_kv["sources_word"] = [{"title": wfile.name, "content_md": md}]
                st.success("sources_word ã‚’æ›´æ–°ã—ã¾ã—ãŸ")
    with st.expander("Excel (.xlsx/.xls/.xlsm)"):
        efile = st.file_uploader("Excel ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ", type=["xlsx", "xls", "xlsm"], key="up_excel")
        if efile is not None:
            md = read_excel_to_markdown(efile)
            st.text_area("ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆMarkdown/CSVï¼‰", value=md, height=160, key="preview_excel")
            if st.button("sources_excel ã«ä¿å­˜", key="save_excel"):
                st.session_state.global_kv["sources_excel"] = [{"title": efile.name, "content_md": md}]
                st.success("sources_excel ã‚’æ›´æ–°ã—ã¾ã—ãŸ")
    with st.expander("CSV (.csv)"):
        cfile = st.file_uploader("CSV ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ", type=["csv"], key="up_csv")
        if cfile is not None:
            md = read_csv_to_markdown(cfile)
            st.text_area("ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆMarkdown/CSVï¼‰", value=md, height=160, key="preview_csv")
            if st.button("sources_csv ã«ä¿å­˜", key="save_csv"):
                st.session_state.global_kv["sources_csv"] = [{"title": getattr(cfile, "name", "data.csv"), "content_md": md}]
                st.success("sources_csv ã‚’æ›´æ–°ã—ã¾ã—ãŸ")
    with st.expander("Text (.txt)"):
        tfile = st.file_uploader("Text ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ", type=["txt"], key="up_text")
        if tfile is not None:
            tx = read_text(tfile)
            st.text_area("ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆãƒ†ã‚­ã‚¹ãƒˆï¼‰", value=tx, height=160, key="preview_text")
            if st.button("sources_text ã«ä¿å­˜", key="save_text"):
                st.session_state.global_kv["sources_text"] = [{"title": getattr(tfile, "name", "text.txt"), "content": tx}]
                st.success("sources_text ã‚’æ›´æ–°ã—ã¾ã—ãŸ")
    with st.expander("Web (URL)"):
        url_text = st.text_area("URLï¼ˆè¤‡æ•°å¯ãƒ»æ”¹è¡ŒåŒºåˆ‡ã‚Šï¼‰", value="", height=100, key="up_web_urls")
        if st.button("å–å¾—", key="fetch_web_btn"):
            urls = [u.strip() for u in (url_text or "").splitlines() if u.strip()]
            results = []
            for u in urls:
                res = read_web_to_markdown(u)
                results.append(res)
            st.session_state["web_fetch_results"] = results
            if results:
                preview = "\n\n---\n\n".join(
                    f"# {r.get('title')}\n\nURL: {r.get('url')}\n\n{r.get('content_md')[:2000]}{'... (truncated)' if len(r.get('content_md',''))>2000 else ''}"
                    for r in results
                )
                st.text_area("ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆMarkdownï¼‰", value=preview, height=200, key="preview_web")
        if st.button("sources_web ã«ä¿å­˜", key="save_web_btn"):
            results = st.session_state.get("web_fetch_results") or []
            items = [
                {"title": r.get("title"), "url": r.get("url"), "content_md": r.get("content_md"), "fetched_at": r.get("fetched_at")}
                for r in results if r.get("ok") and r.get("content_md")
            ]
            st.session_state.global_kv["sources_web"] = items
            st.success(f"sources_web ã‚’æ›´æ–°ã—ã¾ã—ãŸï¼ˆ{len(items)}ä»¶ï¼‰")

    st.markdown("---")
    # å®Ÿè¡Œæ“ä½œï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ç§»å‹•ï¼‰
    st.subheader("å®Ÿè¡Œ")
    if st.button("â–¶ Step å®Ÿè¡Œï¼ˆç¾åœ¨è¡Œï¼‰"):
        run_one_step()
        st.success("Step å®Ÿè¡Œå®Œäº†")
    times = st.number_input("æœ€å¾Œã¾ã§å®Ÿè¡Œ å›æ•°", min_value=1, max_value=100, value=1, step=1)
    if st.button("â© æœ€å¾Œã¾ã§å®Ÿè¡Œï¼ˆæŒ‡å®šå›æ•°ï¼‰"):
        run_to_end_times(times)
        st.success(f"{int(times)} å›å®Ÿè¡Œå®Œäº†")

    st.markdown("---")
    if st.button("å±¥æ­´ã®ã¿åˆæœŸåŒ–ï¼ˆGridä¿æŒï¼‰"):
        for row in st.session_state.grid:
            for ag in row:
                ag.history.clear()
                ag.last_raw = ""
                ag.last_json = None
        st.session_state.current_row = 0
        st.session_state.current_loop_steps = []
        st.session_state.history_loops = []
        st.success("å±¥æ­´åˆæœŸåŒ–ã—ã¾ã—ãŸ")
        safe_rerun()

    if st.button("å…¨ãƒªã‚»ãƒƒãƒˆï¼ˆGridå«ã‚€ï¼‰"):
        st.session_state.clear()
        ensure_state()
        st.success("åˆæœŸåŒ–ã—ã¾ã—ãŸ")
        safe_rerun()


# ============ ãƒ˜ãƒ«ãƒ‘ãƒ¼ï¼ˆè¡¨ç¤ºæŠ‘åˆ¶: Completerãªã©ï¼‰ ============
def is_agent_hidden(ag: Agent) -> bool:
    if ag is None:
        return False
    # æŒ‡å®šIDã§éè¡¨ç¤º
    if ag.id in set(st.session_state.get("hidden_agent_ids", [])):
        return True
    nm = (ag.name or "").strip().lower()
    # Completer/Complete ç³»ã¯è¡¨ç¤ºã‚’éš ã™ï¼ˆæ ã‚‚ä¸è¦ï¼‰
    if nm.startswith("completer") or nm.startswith("complete"):
        return True
    return False


# ============ UI: Main ============
def render_main():
    st.title("ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼")

    base_cols = int(st.session_state.defaults["columns_per_row"])
    for r, row in enumerate(st.session_state.grid):
        st.subheader(f"Step {r+1}")
        tb1, tb2, _tb3 = st.columns([1,1,6], gap="small")
        with tb1:
            if st.button("â¬†ï¸ è¡Œä¸Š", key=f"add_row_up_{r}"):
                st.session_state.grid.insert(r, [new_agent("Agent 1")])
                safe_rerun()
        with tb2:
            if st.button("â¬‡ï¸ è¡Œä¸‹", key=f"add_row_down_{r}"):
                st.session_state.grid.insert(r+1, [new_agent("Agent 1")])
                safe_rerun()

        # å¯è¦–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã¿è¡¨ç¤ºï¼ˆCompleterç­‰ã¯éè¡¨ç¤ºï¼‰
        visible_row = [ag for ag in row if not is_agent_hidden(ag)]
        grid_cols = max(base_cols, len(visible_row))
        cols = st.columns(grid_cols)

        for c, ag in enumerate(visible_row):
            with cols[c]:
                is_current = (r == st.session_state.current_row)

                # ã‚«ãƒ¼ãƒ‰ï¼ˆéè¡¨ç¤ºå¯¾è±¡ã¯ã“ã“ã¾ã§ã§é™¤å¤–æ¸ˆã¿ï¼‰
                card = st.container(border=True)
                with card:
                    # ãƒ˜ãƒƒãƒ€ãƒ¼
                    bar_cls = "agent-topbar is-current" if is_current else "agent-topbar"
                    st.markdown(
                        f'<div class="{bar_cls}">'
                        f'  <div class="agent-title"><span class="agent-chip">S{r+1}-C{c+1}</span>{ag.name}</div>'
                        f'  <div style="display:flex; align-items:center; gap:8px;">'
                        f'    {"<span class=\'agent-badge-current\'>Current</span>" if is_current else ""}'
                        f'    <span style="font-size:12px; opacity:.8;">{ag.model}</span>'
                        f'  </div>'
                        f'</div>',
                        unsafe_allow_html=True
                    )

                    # æœ‰åŠ¹åˆ‡æ›¿
                    en = st.checkbox("æœ‰åŠ¹", value=ag.enabled, key=f"en_{ag.id}")
                    if en != ag.enabled:
                        ag.enabled = en
                        # grid å†…ã®ã‚ªãƒªã‚¸ãƒŠãƒ«å‚ç…§ã‚’æ›´æ–°ï¼ˆè¡Œå†…ã®è©²å½“IDã‚’æ¢ã™ï¼‰
                        for idx, orig in enumerate(st.session_state.grid[r]):
                            if orig.id == ag.id:
                                st.session_state.grid[r][idx] = ag
                                break

                    # ãƒ¡ã‚¿ï¼ˆAgent IDï¼‰ ã¯ãƒ¡ã‚¤ãƒ³ç”»é¢ã‹ã‚‰éè¡¨ç¤º

                    # ãƒœã‚¿ãƒ³è¡Œï¼ˆä¸»è¦ãƒœã‚¿ãƒ³ã®ã¿ï¼‰
                    st.markdown('<div class="btn-row small-btn">', unsafe_allow_html=True)
                    bcols = st.columns(3, gap="small")
                    with bcols[0]:
                        if st.button("â–¶", key=f"run_{ag.id}", help="å®Ÿè¡Œ"):
                            updated = run_agent(ag, r)
                            if isinstance(updated.last_json, dict):
                                patch = updated.last_json.get("kv_patch") or {}
                                _apply_kv_patch(patch)
                                if isinstance(patch.get("Prompt"), dict):
                                    _apply_prompt_patch(patch.get("Prompt") or {}, r)
                                try:
                                    if isinstance(patch.get("target_doc"), str):
                                        updated.last_json.setdefault("kv_patch", {})["target_doc"] = ""
                                    if isinstance(patch.get("Prompt"), dict):
                                        updated.last_json.setdefault("kv_patch", {})["Prompt"] = {}
                                except Exception:
                                    pass
                            # grid å†…ã®ã‚ªãƒªã‚¸ãƒŠãƒ«å‚ç…§ã‚’æ›´æ–°
                            for idx, orig in enumerate(st.session_state.grid[r]):
                                if orig.id == ag.id:
                                    st.session_state.grid[r][idx] = updated
                                    break
                    # 'ï¼‹' ãƒœã‚¿ãƒ³ã¯ãƒ¡ã‚¤ãƒ³ç”»é¢ã‹ã‚‰å‰Šé™¤
                    with bcols[1]:
                        if st.button("ï¼", key=f"del_{ag.id}", help="å‰Šé™¤"):
                            # ã‚°ãƒªãƒƒãƒ‰ä¸Šã®å®Ÿä½ç½®ã‚’æ¢ã—ã¦å‰Šé™¤
                            for idx, orig in enumerate(st.session_state.grid[r]):
                                if orig.id == ag.id:
                                    st.session_state.grid[r].pop(idx)
                                    break
                            if not st.session_state.grid[r]:
                                st.session_state.grid.pop(r)
                            safe_rerun()
                    with bcols[2]:
                        if st.button("ğŸ”", key=f"detail_{ag.id}", help="è©³ç´°"):
                            go_detail(ag.id)
                    st.markdown('</div>', unsafe_allow_html=True)

                    # å‡ºåŠ›ï¼ˆCompleterãªã©ã¯éè¡¨ç¤ºã«ã—ã¦ã„ã‚‹ãŸã‚ã“ã“ã¯ä»–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã¿ï¼‰
                    with st.expander("Parsed", expanded=False):
                        if ag.last_json:
                            st.code(json_pretty(ag.last_json.get("message")), language="json")
                        else:
                            st.info("(no parsed JSON)")
                    with st.expander("Raw", expanded=False):
                        if ag.last_raw:
                            st.code(ag.last_raw)
                        else:
                            st.info("(no raw)")

        if st.button("ï¼‹è¿½åŠ ", key=f"add_tail_{r}"):
            st.session_state.grid[r].append(new_agent(f"Agent {len(st.session_state.grid[r])+1}"))
            safe_rerun()

    st.markdown("---")

    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæ–‡æ›¸ï¼ˆMarkdownï¼‰ã¨ç›®æ¬¡ã‚’ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ä¸‹å´ã«ç§»å‹•
    st.subheader("ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæ–‡æ›¸ï¼ˆMarkdownï¼‰")
    td = st.session_state.global_kv.get("target_doc", "")
    td_new = st.text_area("target_doc", value=td, height=200)
    if st.button("target_doc ã‚’ä¿å­˜"):
        st.session_state.global_kv["target_doc"] = td_new
        st.session_state.global_kv["doc_index"] = compute_doc_index(td_new)
        st.success("æ›´æ–°ã—ã¾ã—ãŸï¼ˆç›®æ¬¡å†ç”Ÿæˆæ¸ˆï¼‰")
    with st.expander("ç›®æ¬¡ï¼ˆè‡ªå‹•ç”Ÿæˆï¼‰", expanded=False):
        st.code(json_pretty(st.session_state.global_kv.get("doc_index")), language="json")

    st.markdown("---")
    st.subheader("ç¾åœ¨ãƒ«ãƒ¼ãƒ—ã®é€²æ—")
    st.code(json_pretty(st.session_state.current_loop_steps), language="json")

    st.subheader("éå»ãƒ«ãƒ¼ãƒ—å±¥æ­´")
    depth = st.slider("è¡¨ç¤ºä»¶æ•°", 0, 10, 3)
    view = st.session_state.history_loops[-depth:] if depth > 0 else []
    st.code(json_pretty(view), language="json")


# ============ UI: Detail ============
def render_detail():
    st.title("ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè©³ç´°")
    agent_id = st.session_state.get("ui_target_agent_id")
    if not agent_id:
        st.warning("ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæœªé¸æŠ")
        if st.button("â† ãƒ¡ã‚¤ãƒ³ã¸"):
            go_main()
        return
    pos = find_agent_pos(agent_id)
    if not pos:
        st.error("ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        if st.button("â† ãƒ¡ã‚¤ãƒ³ã¸"):
            go_main()
        return
    r, c, ag = pos

    top1, top2 = st.columns([1,3])
    with top1:
        if st.button("â† ãƒ¡ã‚¤ãƒ³ã¸"):
            go_main()
    with top2:
        st.write(f"Step {r+1} / åˆ— {c+1}")

    ag.enabled = st.checkbox("æœ‰åŠ¹", value=ag.enabled, key=f"det_en_{ag.id}")
    ag.name = st.text_input("åå‰", value=ag.name, key=f"det_name_{ag.id}")

    k = f"det_prompt_{ag.id}"
    pending_key = f"{k}_pending"
    # If a pending update exists (from a button click), apply it before creating the widget
    if pending_key in st.session_state:
        try:
            pending_val = st.session_state.pop(pending_key)
            # If the widget key already exists, avoid direct assignment (Streamlit forbids it).
            if k in st.session_state:
                # update agent object and grid so next render picks it up
                ag.user_prompt = pending_val
                st.session_state.grid[r][c] = ag
                safe_rerun()
            else:
                st.session_state[k] = pending_val
        except Exception:
            pass
    # Ensure the session_state prompt reflects the agent's prompt before widget creation
    if st.session_state.get(k, None) != (ag.user_prompt or ""):
        st.session_state[k] = ag.user_prompt or ""

    # æŒ‡ç¤ºãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼‰ã‚’å¤§ããã—ã¦æˆ»ã‚‹ãƒœã‚¿ãƒ³ã®ä¸‹å´ã«é…ç½®
    ag.user_prompt = st.text_area("æŒ‡ç¤ºãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼‰", key=k, height=480)
    ag.user_prompt = st.session_state.get(k, "")

    with st.expander("ãƒ¢ãƒ‡ãƒ«è¨­å®š", expanded=False):
        ag.model = st.text_input("model", value=ag.model, key=f"det_model_{ag.id}")
        ag.temperature = float(st.slider("temperature", 0.0, 2.0, float(ag.temperature), 0.1, key=f"det_temp_{ag.id}"))
        ag.max_tokens = int(st.number_input("max_tokens", 128, 8192, int(ag.max_tokens), 64, key=f"det_maxtok_{ag.id}"))
        seed_flag = st.checkbox("seedã‚’ä½¿ã†", value=(ag.seed is not None), key=f"det_seed_f_{ag.id}")
        if seed_flag:
            ag.seed = int(st.number_input("seed", 0, 2**31-1, int(ag.seed or 0), 1, key=f"det_seed_v_{ag.id}"))
        else:
            ag.seed = None

    t_worker = (
        "ã‚ãªãŸã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ”¹å–„æ‹…å½“ã§ã™ã€‚\n"
        "ç›®çš„:\n"
        "- ç¾åœ¨è¡Œã®ã€Œå·¦ã‹ã‚‰1ç•ªï¼Ingestorã€ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ã€å–ã‚Šè¾¼ã¿æ¼ã‚Œé˜²æ­¢ãƒ»ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³å¾¹åº•ãƒ»éæ¨æ¸¬æ–¹é‡ã®æ˜ç¢ºåŒ–ã®è¦³ç‚¹ã§æ”¹å–„ã—ã¦å³æ™‚æ›´æ–°ã—ã¾ã™ã€‚\n"
        "å…¥åŠ›:\n"
        "- ç›´å‰STEPã®å·¦ã‹ã‚‰1ç•ªã®å‡ºåŠ›è¦ç´„: {Context.resp[\"-1\"][0].message}\n"
        "- ã‚°ãƒ­ãƒ¼ãƒãƒ«æƒ…å ±ï¼ˆå–ã‚Šè¾¼ã¿ã‚½ãƒ¼ã‚¹ãƒ»ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³ï¼‰: {Context.global_kv}\n\n"
        "ãƒã‚§ãƒƒã‚¯é …ç›®:\n"
        "- sources_word / sources_excel / sources_csv / sources_text / sources_web ã‚’ã™ã¹ã¦å‚ç…§ã—ã¦ã„ã‚‹ã‹\n"
        "- desired_outline ã‚’è€ƒæ…®ï¼ˆç„¡ã„å ´åˆã¯æ—¢å®šã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³ã‚’æ˜ç¤ºï¼‰\n"
        "- æœ¬æ–‡ã‚’ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«å‘ã‘Markdownã§æ§‹æˆ\n"
        "- æœªçŸ¥ã¯TODOæ˜ç¤ºãƒ»å‡ºå…¸é›†ç´„ãƒ»tokené…æ…®ãƒ»JSONã®ã¿å‡ºåŠ›ï¼ˆã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ç¦æ­¢ï¼‰\n\n"
        "å‡ºåŠ›ã¯JSONã®ã¿:\n"
        "{\n"
        "  \"ok\": true,\n"
        "  \"message\": {\"type\": \"prompt_update\", \"before\": \"(ç¾ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®è¦ç´„ã‚„æ”¹å–„è¦³ç‚¹)\", \"after\": \"(æ”¹å–„å¾Œãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå…¨æ–‡)\"},\n"
        "  \"kv_patch\": {\"Prompt\": {\"0\": {\"0\": \"(æ”¹å–„å¾Œãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå…¨æ–‡)\"}}},\n"
        "  \"meta\": {}\n"
        "}\n"
    )

    t_editor = (
        "ã‚ãªãŸã¯æœ¬æ–‡ç·¨é›†æ‹…å½“ã§ã™ã€‚\n"
        "- ç¾åœ¨ã®æœ¬æ–‡: {Context.global_kv.target_doc}\n"
        "- æœ¬æ–‡ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: {Context.global_kv.doc_index}\n"
        "- ç›´å‰STEPã®å‡ºåŠ›: {Context.resp[\"-1\"]}\n"
        "- æœ›ã¾ã—ã„ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³ï¼ˆä»»æ„ï¼‰: {Context.global_kv.desired_outline}\n\n"
        "ä¸è¶³ã®ç¯€ã‚’è£œã„ã€æ§‹æˆã‚’æ•´ãˆã€æœ¬æ–‡ã®å®Œå…¨ç‰ˆã‚’è¿”ã—ã¦ãã ã•ã„ã€‚JSONã®ã¿:\n"
        "{\n"
        "  \"ok\": true,\n"
        "  \"message\": {\"type\": \"commit\", \"summary\": \"(å¤‰æ›´ç‚¹ã®è¦ç´„)\"},\n"
        "  \"kv_patch\": {\"target_doc\": \"(ä¿®æ­£å¾Œã®æœ¬æ–‡å…¨ä½“)\"},\n"
        "  \"meta\": {}\n"
        "}\n"
    )

    bt1, bt2 = st.columns(2)
    with bt1:
        if st.button("ãƒ†ãƒ³ãƒ—ãƒ¬: Worker", key=f"tmplW_{ag.id}"):
            st.session_state[pending_key] = t_worker
            safe_rerun()
    with bt2:
        if st.button("ãƒ†ãƒ³ãƒ—ãƒ¬: Editor", key=f"tmplE_{ag.id}"):
            st.session_state[pending_key] = t_editor
            safe_rerun()

    st.markdown("#### å·®ã—è¾¼ã¿ã‚·ãƒ§ãƒ¼ãƒˆã‚«ãƒƒãƒˆ")

    def insert_at_cursor(snippet: str):
        base = st.session_state.get(k, "")
        if "{|}" in base:
            new_val = base.replace("{|}", snippet, 1)
        else:
            new_val = base + ("" if base.endswith("\n") or base == "" else "\n") + snippet
        # Store pending update and rerun so the pending value is applied before the text_area widget is created.
        st.session_state[pending_key] = new_val
        safe_rerun()

    rowA = st.columns(6)
    with rowA[0]:
        if st.button("ğŸ“„ TDOC", key=f"ins_tdoc_{ag.id}", use_container_width=True):
            insert_at_cursor("{Context.global_kv.target_doc}")
    with rowA[1]:
        if st.button("ğŸ“˜ WORD", key=f"ins_word_{ag.id}", use_container_width=True):
            insert_at_cursor("{Context.global_kv.sources_word}")
    with rowA[2]:
        if st.button("ğŸ“Š XLSX", key=f"ins_xlsx_{ag.id}", use_container_width=True):
            insert_at_cursor("{Context.global_kv.sources_excel}")
    with rowA[3]:
        if st.button("ğŸ§¾ CSV ", key=f"ins_csv_{ag.id}", use_container_width=True):
            insert_at_cursor("{Context.global_kv.sources_csv}")
    with rowA[4]:
        if st.button("ğŸ“œ TEXT", key=f"ins_text_{ag.id}", use_container_width=True):
            insert_at_cursor("{Context.global_kv.sources_text}")
    with rowA[5]:
        if st.button("ğŸŒ WEB", key=f"ins_web_{ag.id}", use_container_width=True):
            insert_at_cursor("{Context.global_kv.sources_web}")

    rowB = st.columns(4)
    with rowB[0]:
        if st.button("ğŸ“š IDX ", key=f"ins_idx_{ag.id}", use_container_width=True):
            insert_at_cursor("{Context.global_kv.doc_index}")
    with rowB[1]:
        if st.button("ğŸ‘¥ R-1 ", key=f"ins_r_1_{ag.id}", use_container_width=True):
            insert_at_cursor('{Context.resp["-1"]}')
    with rowB[2]:
        if st.button("ğŸ’¬ R1M ", key=f"ins_r1m_{ag.id}", use_container_width=True):
            insert_at_cursor('{Context.resp["-1"][0].message}')
    with rowB[3]:
        if st.button("ğŸ§  PRM1", key=f"ins_kvpatch_prompt_prev1_{ag.id}", use_container_width=True):
            insert_at_cursor(
                'æ¬¡ã®JSONã§ kv_patch.Prompt ã‚’å¿…ãšè¨­å®šã—ã€ç¾åœ¨è¡Œã®å·¦ã‹ã‚‰1ç•ªã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆIngestorï¼‰ã‚’æ›´æ–°ã—ã¦ãã ã•ã„:\\n'
                '{\\n'
                '  "ok": true,\\n'
                '  "message": {"type": "prompt_update", "before": "(è¦ç´„)", "after": "(æ”¹å–„å¾Œãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ)"},\\n'
                '  "kv_patch": {"Prompt": {"0": {"0": "(æ”¹å–„å¾Œãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ)"}}},\\n'
                '  "meta": {}\\n'
                '}'
            )

    ac1, ac2 = st.columns(2)
    with ac1:
        if st.button("â–¶ å®Ÿè¡Œ", key=f"det_run_{ag.id}"):
            updated = run_agent(ag, r)
            if isinstance(updated.last_json, dict):
                patch = updated.last_json.get("kv_patch") or {}
                _apply_kv_patch(patch)
                if isinstance(patch.get("Prompt"), dict):
                    _apply_prompt_patch(patch.get("Prompt") or {}, r)
                try:
                    if isinstance(patch.get("target_doc"), str):
                        updated.last_json.setdefault("kv_patch", {})["target_doc"] = ""
                    if isinstance(patch.get("Prompt"), dict):
                        updated.last_json.setdefault("kv_patch", {})["Prompt"] = {}
                except Exception:
                    pass
            st.session_state.grid[r][c] = updated
            st.success("å®Ÿè¡Œã—ã¾ã—ãŸ")
    with ac2:
        if st.button("âŸ³ ã‚¯ãƒªã‚¢", key=f"det_clear_{ag.id}"):
            ag.last_raw = ""
            ag.last_json = None
            st.session_state.grid[r][c] = ag

    st.caption("Parsed (unified)")
    st.code(json_pretty(ag.last_json) if ag.last_json else "(ãªã—)", language="json")
    st.caption("Raw")
    st.code(ag.last_raw or "(ãªã—)")

    with st.expander("é€ä¿¡ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç¢ºèª", expanded=False):
        ctx = build_context_for_row(r)
        raw_instr = st.session_state.get(k, "")
        expanded_instr = expand_prompt_macros(raw_instr, ctx, row_idx=r)
        system_view = SCHEMA_ENFORCER
        user_view_before = raw_instr
        user_view_after = expanded_instr

        st.caption("Systemï¼ˆã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼šç·¨é›†ä¸å¯ï¼‰")
        st.code(system_view)
        st.caption("Userï¼ˆæŒ‡ç¤ºãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼šå±•é–‹å‰ï¼‰")
        st.code(user_view_before or "(empty)")
        st.caption("Userï¼ˆæŒ‡ç¤ºãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼šå±•é–‹å¾Œï¼å®Ÿéš›ã«é€ä¿¡ï¼‰")
        st.code(user_view_after or "(empty)")

        preview = [{"role": "system", "content": system_view}] + ag.history[-20:] + [{"role": "user", "content": user_view_after}]
        st.caption("é€ä¿¡ messagesï¼ˆå±•é–‹å¾Œï¼‰")
        st.code(json_pretty(preview), language="json")

    st.session_state.grid[r][c] = ag


# ============ ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚° ============
if st.session_state.view == "main":
    render_main()
else:
    render_detail()
